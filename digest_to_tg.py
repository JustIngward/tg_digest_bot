#!/usr/bin/env python3
"""IT‚ÄëDigest Telegram bot ‚Äî v15.0¬†(2025‚Äë04‚Äë22)

üîç  RSS‚Äëonly +¬†–∞–Ω–∞–ª–∏–∑ —Ç–µ–ª–∞ —Å—Ç–∞—Ç—å–∏
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
1.  –°–∫–∞—á–∏–≤–∞–µ–º *–≤—Å–µ* –∑–∞–ø–∏—Å–∏ –∏–∑ RSS‚Äë–ª–µ–Ω—Ç –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N¬†–¥–Ω–µ–π.  
2.  –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º (–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞).  
3.  –ï—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç –µ—â—ë –Ω–µ –Ω–∞–±—Ä–∞–Ω¬†‚Üí –ø–æ–¥—Ç—è–≥–∏–≤–∞–µ–º HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∏ –∏—â–µ–º –∫–ª—é—á‚Äë—Å–ª–æ–≤–∞ –≤¬†—Ç–µ–ª–µ.  
4.  –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1–°¬†‚Äî –º–∏–Ω–∏–º—É–º 2‚ÄØ–ø—É–Ω–∫—Ç–∞, –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω–æ –µ—Å—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç.  
5.  –û—Ç–ø—Ä–∞–≤–ª—è–µ–º HTML‚Äë–¥–∞–π–¥–∂–µ—Å—Ç –≤¬†Telegram.

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏: `requests`, `feedparser`, `beautifulsoup4`, `python-dotenv`, `openai`.
"""
from __future__ import annotations

import os, re, json, datetime as dt, textwrap, requests, feedparser
from urllib.parse import urlparse
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from openai import OpenAI

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CONFIG ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
load_dotenv()
TG_TOKEN   = os.getenv("TG_TOKEN")
CHAT_ID    = os.getenv("CHAT_ID")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
assert TG_TOKEN and CHAT_ID and OPENAI_KEY, "TG_TOKEN, CHAT_ID, OPENAI_API_KEY required"

MODEL            = os.getenv("MODEL", "gpt-4o")
TZ               = dt.timezone(dt.timedelta(hours=3))
MAX_DAYS         = int(os.getenv("MAX_DAYS", 7))
DIGEST_NEWS_CNT  = int(os.getenv("DIGEST_NEWS_CNT", 8))

client = OpenAI()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
ONEC_DOMAINS = {"1c.ru", "infostart.ru", "odysseyconsgroup.com"}
ONEC_KEYS = {
    "1—Å", "1c", "1‚Äë—Å", "1-—Å", "1—Å:erp", "1—Å:–ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ", "wms", "–∑—É–ø",
    "—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤–ª–µ–π", "—É—Ç", "—É–Ω—Ñ", "upp", "unf", "–±—É—Ö–≥–∞–ª—Ç–µ—Ä–∏—è", "odin es", "–æ–¥–∏–Ω—ç—Å"
}

TECH_KEYWORDS = [
    "it", "ai", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω", "—Ü–∏—Ñ—Ä–æ–≤", "–æ–±–ª–∞—á", "–∫–∏–±–µ—Ä", "–±–µ–∑–æ–ø–∞—Å",
    "erp", "crm", "wms", "1—Å", "1c", "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞", "–∏–Ω—Ç–µ–≥—Ä–∞—Ü", "–º–∏–≥—Ä–∞—Ü",
    "–æ–±–Ω–æ–≤–ª–µ–Ω", "devops", "—Ä–∞–∑—Ä–∞–±–æ—Ç", "api", "–º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å", "kubernetes",
] + list(ONEC_KEYS)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ RSS‚Äë–ª–µ–Ω—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
RSS_FEEDS = [
    "https://habr.com/ru/rss/all/all/?fl=ru",
    "https://vc.ru/rss",
    "https://www.rbc.ru/technology/rss/full/",
    "https://tadviser.ru/index.php/–°—Ç–∞—Ç—å—è:–ù–æ–≤–æ—Å—Ç–∏?feed=rss",
    "https://novostiitkanala.ru/feed/",
    "https://www.kommersant.ru/RSS/section-tech.xml",
    "https://1c.ru/news/all.rss",
    "https://infostart.ru/rss/news/",
    "https://trends.rbc.ru/trends.rss",
    "https://rusbase.com/feed/",
]

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Helpers ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
CUTOFF = dt.datetime.utcnow() - dt.timedelta(days=MAX_DAYS)
RE_TAG = re.compile(r"<[^>]+>")


def simple_text(html: str) -> str:
    soup = BeautifulSoup(html, "html.parser")
    return soup.get_text(separator=" ").lower()


def has_kw(text: str) -> bool:
    return any(k in text for k in TECH_KEYWORDS)


def rss_fetch() -> list[dict]:
    arts: list[dict] = []
    for url in RSS_FEEDS:
        try:
            feed = feedparser.parse(url)
        except Exception:
            continue
        for e in feed.entries:
            link  = getattr(e, "link", "")
            title = getattr(e, "title", "")
            date_str = getattr(e, "published", "")[:10]
            try:
                date_obj = dt.datetime.strptime(date_str, "%Y-%m-%d")
            except Exception:
                date_obj = CUTOFF
            if date_obj < CUTOFF:
                continue
            arts.append({"title": title, "url": link, "date": date_str})
    # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –Ω–æ–≤–µ–µ‚Äë–≤–≤–µ—Ä—Ö
    return sorted(arts, key=lambda a: a["date"], reverse=True)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è 2‚Äë—ç—Ç–∞–ø–∞ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def filter_stage(arts: list[dict]) -> list[dict]:
    # 1. –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
    flagged = [a for a in arts if any(k in a["title"].lower() for k in TECH_KEYWORDS)]
    if len(flagged) >= DIGEST_NEWS_CNT:
        return flagged[:DIGEST_NEWS_CNT]

    # 2. –¥–æ–∫–∏–¥—ã–≤–∞–µ–º –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
    for a in arts:
        if a in flagged:  # —É–∂–µ –µ—Å—Ç—å
            continue
        try:
            html = requests.get(a["url"], timeout=10).text
        except Exception:
            continue
        if has_kw(simple_text(html)):
            flagged.append(a)
        if len(flagged) >= DIGEST_NEWS_CNT:
            break
    return flagged

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç 1–° ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def is_onec(a: dict) -> bool:
    t = a["title"].lower()
    return any(k in t for k in ONEC_KEYS) or urlparse(a["url"]).netloc in ONEC_DOMAINS


def select_articles(all_articles: list[dict]) -> list[dict]:
    filtered = filter_stage(all_articles)
    onec = [a for a in filtered if is_onec(a)]
    other = [a for a in filtered if not is_onec(a)]
    # –º–∏–Ω–∏–º—É–º 2 1–°‚Äë–Ω–æ–≤–æ—Å—Ç–∏, –µ—Å–ª–∏ –µ—Å—Ç—å
    selected = (onec[:2] if len(onec) >= 2 else onec) + other
    return selected[:DIGEST_NEWS_CNT]

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ GPT‚ÄëPrompt & call ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def build_prompt(arts: list[dict]) -> str:
    today = dt.datetime.now(TZ).strftime("%d %b %Y")
    return textwrap.dedent(f"""
        –ù–∞ –≤—Ö–æ–¥–µ JSON —Å—Ç–∞—Ç–µ–π (title, url, date). –°–æ—Å—Ç–∞–≤—å –¥–∞–π–¥–∂–µ—Å—Ç HTML‚ÄëMarkdown:
        ‚Ä¢ –¢—Ä–∏ —Å–µ–∫—Ü–∏–∏:
          üåç <b>GLOBAL¬†IT</b>\nüá∑üá∫ <b>RU¬†TECH</b>\nüü° <b>1–°¬†–≠–ö–û–°–ò–°–¢–ï–ú–ê</b>
        ‚Ä¢ –§–æ—Ä–º–∞—Ç —Å—Ç—Ä–æ–∫–∏: "- <b>–ó–∞–≥–æ–ª–æ–≤–æ–∫</b> ‚Äî 1‚Äë2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. <a href=\"url\">–ò—Å—Ç–æ—á–Ω–∏–∫</a> (DD.MM.YYYY)".
        ‚Ä¢ –ï—Å–ª–∏ —Å—Ç–∞—Ç–µ–π –º–µ–Ω—å—à–µ {DIGEST_NEWS_CNT}, –≤—ã–≤–æ–¥–∏ —Å—Ç–æ–ª—å–∫–æ, —Å–∫–æ–ª—å–∫–æ –µ—Å—Ç—å.
        ‚Ä¢ –í –∫–æ–Ω—Ü–µ –±–ª–æ–∫ "üí° <b>Insight</b>:" ‚Äî 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
        JSON: ```{json.dumps(arts, ensure_ascii=False)}```
    """).strip()


def build_digest(prompt: str) -> str:
    r = client.chat.completions.create(
        model=MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.4,
        max_tokens=1000,
    )
    return r.choices[0].message.content.strip()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Telegram ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

import html as _html, re as _re

def _sanitize(html_txt: str) -> str:
    """–≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º & –≤–Ω—É—Ç—Ä–∏ href –∏ < > –≤–Ω—É—Ç—Ä–∏ —Ç–µ–∫—Å—Ç–∞, –æ—Å—Ç–∞–≤–ª—è—è —Ç–µ–≥–∏ <b>, <i>, <a>."""
    # 1) & –≤ —Å—Å—ã–ª–∫–∞—Ö ‚Üí &amp;
    def _amp(m):
        url = m.group(1).replace("&", "&amp;")
        return f'href="{url}"'
    html_txt = _re.sub(r'href="([^"]+)"', _amp, html_txt)
    # 2) –≠–∫—Ä–∞–Ω–∏—Ä—É–µ–º < –∏ > –≤–Ω–µ —Ç–µ–≥–æ–≤
    safe = []
    for part in _re.split(r'(<[^>]+>)', html_txt):
        if part.startswith('<'):
            safe.append(part)
        else:
            safe.append(_html.escape(part))
    return ''.join(safe)

def send_telegram(html: str):
    api = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    for i in range(0, len(html), 3800):
        chunk = _sanitize(html[i:i+3800])
        r = requests.post(api, json={
            "chat_id": CHAT_ID,
            "text": chunk,
            "parse_mode": "HTML",
            "disable_web_page_preview": False,
        }, timeout=20)
        print("TG", r.status_code, r.text[:90])
        r.raise_for_status()(0, len(html), 3800):
        chunk = html[i:i+3800]
        r = requests.post(api, json={
            "chat_id": CHAT_ID,
            "text": chunk,
            "parse_mode": "HTML",
            "disable_web_page_preview": False,
        }, timeout=20)
        print("TG", r.status_code, r.text[:70])
        r.raise_for_status()

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MAIN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def main():
    arts = select_articles(rss_fetch())
    digest = build_digest(build_prompt(arts))
    send_telegram(digest)
    print(f"Digest sent with {len(arts)} articles ‚úîÔ∏é")

if __name__ == "__main__":
    main()
