#!/usr/bin/env python3
"""ITâ€‘Digest Telegram bot â€” v16.1Â (2025â€‘04â€‘22)
RSSâ€‘only, asyncâ€‘HTML, GPTâ€‘Ñ€Ð°Ð½Ð¶, Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚ 1Ð¡ (â‰¥40â€¯%).
"""
from __future__ import annotations

import asyncio, datetime as dt, html as _html, json, os, re, textwrap
from urllib.parse import urlparse

import feedparser, httpx, requests
from dotenv import load_dotenv
from bs4 import BeautifulSoup
from openai import OpenAI

# â”€â”€â”€â”€â”€ ENV / CONFIG â”€â”€â”€â”€â”€
load_dotenv()
TG_TOKEN   = os.getenv("TG_TOKEN")
CHAT_ID    = os.getenv("CHAT_ID")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
assert TG_TOKEN and CHAT_ID and OPENAI_KEY, "TG_TOKEN, CHAT_ID, OPENAI_API_KEY required"

MODEL        = os.getenv("MODEL", "gpt-4o")
TZ           = dt.timezone(dt.timedelta(hours=3))
MAX_DAYS     = 7               # ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð´Ð½ÐµÐ¹ Ð½Ð°Ð·Ð°Ð´ Ð±ÐµÑ€Ñ‘Ð¼
MAX_PER_FEED = 50              # Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð¸Ð· ÐºÐ°Ð¶Ð´Ð¾Ð¹ Ð»ÐµÐ½Ñ‚Ñ‹
MAX_HTML     = 250             # Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ HTMLâ€‘ÑÐºÐ°Ñ‡Ð¸Ð²Ð°Ð½Ð¸Ð¹
DIGEST_MIN   = 8
DIGEST_MAX   = 12
PERC_ONEC    = 0.4             # Ð´Ð¾Ð»Ñ 1Ð¡â€‘Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð² Ð´Ð°Ð¹Ð´Ð¶ÐµÑÑ‚Ðµ

client = OpenAI()
CUTOFF = dt.datetime.utcnow() - dt.timedelta(days=MAX_DAYS)

# â”€â”€â”€â”€â”€ ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° â”€â”€â”€â”€â”€
ONEC_DOMAINS = {"1c.ru", "infostart.ru", "odysseyconsgroup.com"}
ONEC_KEYS = {
    "1Ñ", "1c", "1â€‘Ñ", "1-Ñ", "1Ñ:erp", "erp", "Ð·ÑƒÐ¿", "ÑƒÐ½Ñ„",
    "ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ñ‚Ð¾Ñ€Ð³Ð¾Ð²Ð»ÐµÐ¹", "Ð±ÑƒÑ…Ð³Ð°Ð»Ñ‚ÐµÑ€Ð¸Ñ", "wms",
}
INCLUDE = set(ONEC_KEYS) | {
    "ai", "devops", "Ð¾Ð±Ð»Ð°Ñ‡", "Ñ†Ð¸Ñ„Ñ€Ð¾Ð²", "Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†", "Ð¼Ð¸Ð³Ñ€Ð°Ñ†",
    "kubernetes", "crm", "Ð°Ð²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ð·Ð°",
}
EXCLUDE = {
    "crypto", "iphone", "lifestyle", "ÑˆÐ¾ÐºÐ¾Ð»Ð°Ð´", "Ñ„Ð¸ÑÑ‚Ð°ÑˆÐº", "Ð°Ð²Ñ‚Ð¾",
    "Ð±Ð¸Ñ€Ð¶Ð°", "Ð±Ð°Ð½ÐºÐ¾Ð¼Ð°Ñ‚", "Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ",
}

# â”€â”€â”€â”€â”€ RSSâ€‘Ð»ÐµÐ½Ñ‚Ñ‹ â”€â”€â”€â”€â”€
RSS_FEEDS = [
    "https://habr.com/ru/rss/all/all/?fl=ru",
    "https://vc.ru/rss",
    "https://www.rbc.ru/technology/rss/full/",
    "https://tadviser.ru/index.php/Ð¡Ñ‚Ð°Ñ‚ÑŒÑ:ÐÐ¾Ð²Ð¾ÑÑ‚Ð¸?feed=rss",
    "https://novostiitkanala.ru/feed/",
    "https://www.kommersant.ru/RSS/section-tech.xml",
    "https://1c.ru/news/all.rss",
    "https://infostart.ru/rss/news/",
    "https://trends.rbc.ru/trends.rss",
    "https://rusbase.com/feed/",
]

# â”€â”€â”€â”€â”€ Helper functions â”€â”€â”€â”€â”€

def plain(html: str) -> str:
    return BeautifulSoup(html, "html.parser").get_text(" ").lower()

async def fetch_html(url: str, client: httpx.AsyncClient) -> str | None:
    try:
        r = await client.get(url, timeout=6)
        return r.text if r.status_code == 200 else None
    except Exception:
        return None

# â”€â”€â”€â”€â”€ Stage 0: Collect raw (50 Ã— feeds) â”€â”€â”€â”€â”€

def collect_raw():
    pool_onec, pool_other = [], []
    for feed in RSS_FEEDS:
        try:
            fp = feedparser.parse(feed)
        except Exception:
            continue
        for entry in fp.entries[:MAX_PER_FEED]:
            link = entry.get("link", "")
            title = entry.get("title", "")
            date_str = (entry.get("published") or entry.get("updated") or entry.get("dc_date") or "")[:10]
            try:
                d = dt.datetime.strptime(date_str, "%Y-%m-%d")
            except Exception:
                d = dt.datetime.utcnow()
            if d < CUTOFF:
                continue
            rec = {
                "title": title,
                "url": link,
                "date": d.strftime("%d.%m.%Y"),
                "t": title.lower(),
            }
            target = pool_onec if (urlparse(link).netloc in ONEC_DOMAINS or any(k in rec["t"] for k in ONEC_KEYS)) else pool_other
            target.append(rec)
    return pool_onec, pool_other

# â”€â”€â”€â”€â”€ Stage 1: Title filter â”€â”€â”€â”€â”€

def title_filter(lst):
    ok = []
    for a in lst:
        t = a["t"]
        if any(w in t for w in EXCLUDE):
            continue
        if any(k in t for k in INCLUDE):
            ok.append(a)
    return ok

# â”€â”€â”€â”€â”€ Stage 2: Async HTML filter â”€â”€â”€â”€â”€

async def body_filter(cand: list[dict]):
    subset = cand[:MAX_HTML]
    async with httpx.AsyncClient(follow_redirects=True, headers={"User-Agent": "Mozilla/5.0"}) as cl:
        pages = await asyncio.gather(*[fetch_html(a["url"], cl) for a in subset])
    out = []
    for art, html in zip(subset, pages):
        if html and any(k in plain(html) for k in INCLUDE):
            out.append(art)
    return out

# â”€â”€â”€â”€â”€ Stage 3: GPT ranking â”€â”€â”€â”€â”€

def gpt_rank(pool: list[dict]):
    prompt = (
        "ÐžÑ†ÐµÐ½Ð¸ Ð¿Ð¾ ÑˆÐºÐ°Ð»Ðµ 0â€‘10 Ð²Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð´Ð»Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ‚Ð¾Ñ€Ð° 1Ð¡. "
        "ÐžÑ‚Ð²ÐµÑ‚ JSON Ð²Ð¸Ð´Ð° {\"idx\":score}. ÐÐµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐ¹ Ð½Ð¸Ñ‡ÐµÐ³Ð¾."
    )
    mini = [{"idx": i, "title": a["title"], "url": a["url"]} for i, a in enumerate(pool)]
    resp = client.chat.completions.create(
        model=MODEL,
        messages=[{"role": "user", "content": prompt + json.dumps(mini, ensure_ascii=False)}],
        temperature=0,
        max_tokens=300,
    )
    try:
        scores = json.loads(resp.choices[0].message.content)
    except Exception:
        scores = {str(i): 5 for i in range(len(pool))}
    ranked = sorted(pool, key=lambda x: -scores.get(str(pool.index(x)), 0))
    return ranked[: DIGEST_MAX * 2]

# â”€â”€â”€â”€â”€ Layout final list â”€â”€â”€â”€â”€

def layout(arts):
    onec = [a for a in arts if (urlparse(a["url"]).netloc in ONEC_DOMAINS or any(k in a["t"] for k in ONEC_KEYS))]
    other = [a for a in arts if a not in onec]
    need_onec = max(3, int(DIGEST_MAX * PERC_ONEC))
    final = (onec[:need_onec] + other)[:DIGEST_MAX]
    return final

# â”€â”€â”€â”€â”€ Prompt for final digest â”€â”€â”€â”€â”€

def build_prompt(arts):
    today = dt.datetime.now(TZ).strftime("%d %b %Y")
    return textwrap.dedent(
        f"""
        Ð¢Ñ‹ â€” Ñ€ÐµÐ´Ð°ÐºÑ‚Ð¾Ñ€ B2Bâ€‘Ð´Ð°Ð¹Ð´Ð¶ÐµÑÑ‚Ð° Ð´Ð»Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ‚Ð¾Ñ€Ð¾Ð² 1Ð¡. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¢ÐžÐ›Ð¬ÐšÐž Ð´Ð°Ð½Ð½Ñ‹Ðµ JSON, Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹.
        Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ: 8â€‘12 ÑÑ‚Ñ€Ð¾Ðº; ÑÐµÐºÑ†Ð¸Ð¸ ðŸŒ/ðŸ‡·ðŸ‡º/ðŸŸ¡; â‰¥40â€¯% ÑÑ‚Ñ€Ð¾Ðº Ð¿Ñ€Ð¾ 1Ð¡; Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ "- <b>Ð—Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº</b> â€” â€¦ (DD.MM.YYYY)".
        Ð’ ÐºÐ¾Ð½Ñ†Ðµ Ð±Ð»Ð¾Ðº "ðŸ’¡ <b>Insight</b>:" â€” 2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ.
        JSON: ```{json.dumps(arts, ensure_ascii=False)}```
        """
    ).strip()

# â”€â”€â”€â”€â”€ Sanitize + Telegram send â”€â”€â”€â”€â”€

def sanitize(html_txt: str) -> str:
    html_txt = re.sub(r'href="([^"]+)"', lambda m: f'href="{m.group(1).replace("&", "&amp;")}"', html_txt)
    parts = re.split(r'(<[^>]+>)', html_txt)
    return ''.join(p if p.startswith('<') else _html.escape(p) for p in parts)


def send(html: str):
    api = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    for i in range(0, len(html), 3800):
        chunk = sanitize(html[i : i + 3800])
        r = requests.post(api, json={"chat_id": CHAT_ID, "text": chunk, "parse_mode": "HTML"})
        r.raise_for_status()

# â”€â”€â”€â”€â”€ MAIN â”€â”€â”€â”€â”€

def main():
    pool_onec, pool_other = collect_raw()
    pool_onec = title_filter(pool_onec)[: int(PERC_ONEC * 500)]
    pool_other = title_filter(pool_other)[: 500 - len(pool_onec)]
    merged = pool_onec + pool_other

    filtered = asyncio.run(body_filter(merged))
    ranked = gpt_rank(filtered)
    digest_list = layout(ranked)

    prompt = build_prompt(digest_list)
    resp = client.chat.completions.create(
        model=MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
        max_tokens=1200,
    )
    send(resp.choices[0].message.content.strip())

if __name__ == "__main__":
    main()
