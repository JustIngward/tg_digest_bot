#!/usr/bin/env python3
"""ITâ€‘Digest Telegram bot â€” v16.0Â (2025â€‘04â€‘22)

ğŸ†•  Â«50Ã—10Â»Â RSSâ€‘Ğ·Ğ°Ñ…Ğ²Ğ°Ñ‚Â â†’Â asyncâ€‘HTMLÂ â†’Â GPTâ€‘Ñ€Ğ°Ğ½Ğ¶
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
*  **Ğ¨Ğ¸Ñ€Ğ¾ĞºĞ¸Ğ¹ ÑĞ±Ğ¾Ñ€**: Ğ´Ğ¾Â 50Â ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ¸Ğ· ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ»ĞµĞ½Ñ‚Ñ‹ (â‰ˆ500).
*  **Ğ‘Ğ°Ğ»Ğ°Ğ½Ñ 40â€¯% 1Ğ¡**: Ğ´Ğ²Ğ° Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ñ… Ğ¿ÑƒĞ»Ğ°, Ğ´Ğ¾Ğ±Ğ¾Ñ€ Â«Ñ…Ğ²Ğ¾ÑÑ‚Ğ¾Ğ¼Â» Ğ¸Ğ· other.
*  **Ğ”Ğ²ÑƒÑ…ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ²Ñ‹Ğ¹ Ğ¾Ñ‚Ğ±Ğ¾Ñ€**
   1. fastÂ â€” Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾â€†title (include/exclude ĞºĞ»ÑÑ‡Ğ¸).
   2. slowÂ â€” async ÑĞºÑ€ĞµĞ¹Ğ¿Â HTML (httpx,Â 20Â ĞºĞ¾Ğ½Ğ½ĞµĞºÑ‚Ğ¾Ğ²).
*  **GPTâ€‘Ñ€Ğ°Ğ½Ğ¶**: Ğ¾Ğ´Ğ¸Ğ½ Ğ²Ñ‹Ğ·Ğ¾Ğ²Â 4o Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ scoreÂ 0â€‘10; Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ²ĞµÑ€Ñ…Ğ½ÑÑÂ Ğ¿Ğ¾Ğ»Ğ¾Ğ²Ğ¸Ğ½Ñƒ.
*  Ğ˜Ñ‚Ğ¾Ğ³Â â€” 8â€‘12Â ÑÑ‚Ñ€Ğ¾Ğº, â‰¥Â 40â€¯% 1Ğ¡ (Ğ¼Ğ¸Ğ½Â 3Â Ğ¿ÑƒĞ½ĞºÑ‚Ğ°).
*  Ğ–Ñ‘ÑÑ‚ĞºĞ¾: Â«Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ„Ğ°ĞºÑ‚Ñ‹ Ğ¸Ğ· Ğ²Ñ…Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ JSON, Ğ½ĞµÂ Ğ¿Ñ€Ğ¸Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹Â».  
*  HTMLâ€‘safe Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ°.
"""
from __future__ import annotations

import os, re, json, asyncio, datetime as dt, textwrap, html as _html
from collections import defaultdict
from urllib.parse import urlparse

import feedparser, httpx, python_dotenv
from bs4 import BeautifulSoup
from openai import OpenAI

# â”€â”€â”€â”€â”€ CONFIG â”€â”€â”€â”€â”€
python_dotenv.load_dotenv()
TG_TOKEN  = os.getenv("TG_TOKEN")
CHAT_ID   = os.getenv("CHAT_ID")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
assert TG_TOKEN and CHAT_ID and OPENAI_KEY, "env vars missing"

MODEL      = os.getenv("MODEL", "gpt-4o")
TZ         = dt.timezone(dt.timedelta(hours=3))
MAX_DAYS   = 7
MAX_PER_FEED = 50
MAX_HTML   = 250
DIGEST_MIN = 8
DIGEST_MAX = 12
PERC_ONEC  = 0.4   # 40Â %

client = OpenAI()

# â”€â”€â”€â”€â”€ KEYS â”€â”€â”€â”€â”€
ONEC_DOMAINS = {"1c.ru", "infostart.ru", "odysseyconsgroup.com"}
ONEC_KEYS = {"1Ñ", "1c", "1Ñ:erp", "erp", "Ğ·ÑƒĞ¿", "ÑƒĞ½Ñ„", "ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»ĞµĞ¹", "Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ñ"}
INCLUDE = set(ONEC_KEYS)|{"ai","devops","Ğ¾Ğ±Ğ»Ğ°Ñ‡","Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²","Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†","Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†","kubernetes","crm","wms"}
EXCLUDE = {"crypto","iphone","ÑˆĞ¾ĞºĞ¾Ğ»Ğ°Ğ´","lifestyle","Ğ°Ğ²Ñ‚Ğ¾","Ğ±Ğ¸Ñ€Ğ¶Ğ°","Ğ±Ğ°Ğ½ĞºĞ¾Ğ¼Ğ°Ñ‚"}

# â”€â”€â”€â”€â”€ RSS FEEDS â”€â”€â”€â”€â”€
RSS_FEEDS = [
    "https://habr.com/ru/rss/all/all/?fl=ru","https://vc.ru/rss","https://www.rbc.ru/technology/rss/full/",
    "https://tadviser.ru/index.php/Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ:ĞĞ¾Ğ²Ğ¾ÑÑ‚Ğ¸?feed=rss","https://novostiitkanala.ru/feed/",
    "https://www.kommersant.ru/RSS/section-tech.xml","https://1c.ru/news/all.rss",
    "https://infostart.ru/rss/news/","https://trends.rbc.ru/trends.rss","https://rusbase.com/feed/",
]
CUTOFF = dt.datetime.utcnow() - dt.timedelta(days=MAX_DAYS)

# â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€
RE_TAG = re.compile(r"<[^>]+>")

def plain(html:str)->str:
    return BeautifulSoup(html,"html.parser").get_text(" ").lower()

async def fetch_html(url:str, client:httpx.AsyncClient)->str|None:
    try:
        r = await client.get(url, timeout=6)
        if r.status_code==200:
            return r.text
    except Exception:
        return None

# â”€â”€â”€â”€â”€ stage 0 : collect 50 per feed â”€â”€â”€â”€â”€

def collect_raw():
    onec_pool, other_pool = [], []
    for feed in RSS_FEEDS:
        try:
            fp = feedparser.parse(feed)
        except Exception:
            continue
        count=0
        for e in fp.entries:
            if count>=MAX_PER_FEED: break
            link=e.get("link","")
            title=e.get("title","")
            date_str=(e.get("published") or e.get("updated") or "")[:10]
            try:
                d=dt.datetime.strptime(date_str,"%Y-%m-%d")
            except: d=dt.datetime.utcnow()
            if d<CUTOFF: continue
            rec={"title":title,"url":link,"date":d.strftime("%d.%m.%Y"),"t":title.lower()}
            (onec_pool if any(dom in link for dom in ONEC_DOMAINS) or any(k in rec["t"] for k in ONEC_KEYS) else other_pool).append(rec)
            count+=1
    return onec_pool, other_pool

# â”€â”€â”€â”€â”€ stage 1 : title filter â€” keep relevant â”€â”€â”€â”€â”€

def title_filter(lst):
    out=[]
    for a in lst:
        t=a["t"]
        if any(x in t for x in EXCLUDE):
            continue
        if any(k in t for k in INCLUDE):
            out.append(a)
    return out

# â”€â”€â”€â”€â”€ stage 2 : async body filter â”€â”€â”€â”€â”€

async def body_filter(candidates:list[dict]):
    selected=candidates.copy()
    if len(selected)>=MAX_HTML: selected=selected[:MAX_HTML]
    async with httpx.AsyncClient(follow_redirects=True, headers={"User-Agent":"Mozilla/5.0"}) as c:
        tasks=[fetch_html(a["url"],c) for a in selected]
        pages=await asyncio.gather(*tasks)
    out=[]
    for a,html in zip(selected,pages):
        if html and any(k in plain(html) for k in INCLUDE):
            out.append(a)
    return out

# â”€â”€â”€â”€â”€ stage 3 : GPT ranking â”€â”€â”€â”€â”€

def gpt_rank(pool:list[dict]):
    prompt="ĞÑ†ĞµĞ½Ğ¸ Ğ¿Ğ¾ ÑˆĞºĞ°Ğ»Ğµ 0â€‘10 Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ° 1Ğ¡. ĞÑ‚Ğ²ĞµÑ‚ JSON Ğ²Ğ¸Ğ´Ğ° {\"idx\":score}. ĞĞµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞ¹ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾.""
    mini=[{"idx":i,"title":a["title"],"url":a["url"]} for i,a in enumerate(pool)]
    resp=client.chat.completions.create(model=MODEL,messages=[{"role":"user","content":prompt+json.dumps(mini,ensure_ascii=False)}],temperature=0,max_tokens=300)
    try:
        scores=json.loads(resp.choices[0].message.content)
    except: scores={str(i):5 for i in range(len(pool))}
    ranked=sorted(pool,key=lambda x:-scores.get(str(pool.index(x)),0))
    return ranked[:DIGEST_MAX*2]  # Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ğ¼ Ğ·Ğ°Ğ¿Ğ°Ñ

# â”€â”€â”€â”€â”€ layout â”€â”€â”€â”€â”€

def layout(arts:list[dict]):
    onec=[a for a in arts if any(k in a["t"] for k in ONEC_KEYS) or urlparse(a["url"]).netloc in ONEC_DOMAINS]
    other=[a for a in arts if a not in onec]
    need_onec=max(3,int(DIGEST_MAX*PERC_ONEC))
    final=(onec[:need_onec]+other)[:DIGEST_MAX]
    return final

# â”€â”€â”€â”€â”€ prompt / digest / send (reuse v15.2) â”€â”€â”€â”€â”€

def build_prompt(arts):
    today=dt.datetime.now(TZ).strftime("%d %b %Y")
    return textwrap.dedent(f"""
        Ğ¢Ñ‹ â€” Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¾Ñ€ B2Bâ€‘Ğ´Ğ°Ğ¹Ğ´Ğ¶ĞµÑÑ‚Ğ° Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² 1Ğ¡. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ JSON, Ğ½Ğµ Ğ²Ñ‹Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹.
        Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: 8â€‘12 ÑÑ‚Ñ€Ğ¾Ğº; ÑĞµĞºÑ†Ğ¸Ğ¸ ğŸŒ/ğŸ‡·ğŸ‡º/ğŸŸ¡; 40â€¯% ÑÑ‚Ñ€Ğ¾Ğº Ğ¿Ñ€Ğ¾ 1Ğ¡; Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ "- <b>Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº</b> â€” â€¦".
        Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ Ğ±Ğ»Ğ¾Ğº Insight.
        JSON: ```{json.dumps(arts,ensure_ascii=False)}```
    """)

def sanitize(html_txt:str):
    html_txt=re.sub(r'href="([^"]+)"',lambda m:f'href="{m.group(1).replace("&","&amp;")}"',html_txt)
    parts=re.split(r'(<[^>]+>)',html_txt)
    return ''.join(p if p.startswith('<') else _html.escape(p) for p in parts)


def send(html:str):
    api=f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    for i in range(0,len(html),3800):
        chunk=sanitize(html[i:i+3800])
        r=requests.post(api,json={"chat_id":CHAT_ID,"text":chunk,"parse_mode":"HTML"})
        r.raise_for_status()

# â”€â”€â”€â”€â”€ MAIN â”€â”€â”€â”€â”€

def main():
    pool_onec,pool_other=collect_raw()
    pool_onec=title_filter(pool_onec)
    pool_other=title_filter(pool_other)
    # Ğ±Ğ°Ğ»Ğ°Ğ½Ñ
    target_onec=int(PERC_ONEC*500)
    pool_other=pool_other[:500-len(pool_onec)]
    merged=pool_onec+pool_other
    # html stage
    filtered=asyncio.run(body_filter(merged))
    ranked=gpt_rank(filtered)
    digest_list=layout(ranked)
    prompt=build_prompt(digest_list)
    result=client.chat.completions.create(model=MODEL,messages=[{"role":"user","content":prompt}],temperature=0.3,max_tokens=1200)
    send(result.choices[0].message.content.strip())

if __name__=="__main__":
    main()
