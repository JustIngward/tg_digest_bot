#!/usr/bin/env python3
"""ITâ€‘Digest Telegram bot â€”Â v17.1Â (2025â€‘04â€‘24)

Ğ¤Ğ¸ĞºÑÑ‹ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¿ÑƒÑÑ‚Ğ¾Ğ³Ğ¾ Ğ´Ğ°Ğ¹Ğ´Ğ¶ĞµÑÑ‚Ğ°:
â€¢ bodyâ€‘filter Ğ±Ğ¾Ğ»ÑŒÑˆĞµ ĞĞ• Ğ¾Ñ‚Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµÑ‚ 1Ğ¡â€‘ÑÑ‚Ğ°Ñ‚ÑŒĞ¸, Ğ´Ğ°Ğ¶Ğµ ĞµÑĞ»Ğ¸ Ğ²Â HTML Ğ½ĞµÑ‚ ĞºĞ»ÑÑ‡Ğ°.
â€¢ need_onecÂ â‰¥â€¯1 (Ğ° Ğ½Ğµ 3)Â â€” Ğ´Ğ°Ğ¹Ğ´Ğ¶ĞµÑÑ‚ ÑĞ¾Ğ±ĞµÑ€Ñ‘Ñ‚ÑÑ, Ğ´Ğ°Ğ¶Ğµ ĞµÑĞ»Ğ¸ 1Ğ¡â€‘ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ° Ğ¼Ğ°Ğ»Ğ¾.
â€¢ fallback: ĞµÑĞ»Ğ¸ Ğ¿Ğ¾ÑĞ»Ğµ Ğ²ÑĞµÑ… Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ² <â€¯DIGEST_MIN ÑÑ‚Ñ€Ğ¾ĞºÂ â†’Â Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ Â«Ğ·Ğ° Ğ½ĞµĞ´ĞµĞ»Ñ Ğ½ĞµÑ‚ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹Â» Ğ¸ Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ğ±ĞµĞ·Â Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸.
"""
from __future__ import annotations

import asyncio, datetime as dt, html as _html, json, os, re, textwrap
from urllib.parse import urlparse

import feedparser, httpx, requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv
from openai import OpenAI

# â”€â”€â”€ CONFIG â”€â”€â”€
load_dotenv()
TG_TOKEN = os.getenv("TG_TOKEN"); CHAT_ID = os.getenv("CHAT_ID"); OPENAI_KEY = os.getenv("OPENAI_API_KEY")
assert TG_TOKEN and CHAT_ID and OPENAI_KEY, "TG_TOKEN, CHAT_ID, OPENAI_API_KEY required"
MODEL = os.getenv("MODEL", "gpt-4o"); TZ = dt.timezone(dt.timedelta(hours=3))
MAX_DAYS, MAX_PER_FEED, MAX_HTML = 7, 50, 250
DIGEST_MIN, DIGEST_MAX = 8, 12; PERC_ONEC = 0.4
client = OpenAI(); CUTOFF = dt.datetime.utcnow() - dt.timedelta(days=MAX_DAYS)

# â”€â”€â”€ KEYWORDS â”€â”€â”€
ONEC_DOMAINS = {"1c.ru", "infostart.ru", "odysseyconsgroup.com"}
ONEC_KEYS = {
    "1Ñ", "1c", "1Ñ:erp", "erp", "1Ñ:ÑƒÑ…", "ÑƒÑ…", "erpÑƒÑ…", "erpâ€‘ÑƒÑ…",
    "Ğ·ÑƒĞ¿", "ÑƒĞ½Ñ„", "ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»ĞµĞ¹", "ut", "ut11", "Ğ±ÑƒÑ…Ğ³Ğ°Ğ»Ñ‚ĞµÑ€Ğ¸Ñ",
    "wms", "Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´ÑÑ‚Ğ²", "Ğ°Ğ³Ñ€Ğ¾", "ÑĞµĞ»ÑŒÑ…Ğ¾Ğ·", "Ğ°Ğ³Ñ€Ğ°Ñ€Ğ½", "Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»"
}
EVENT_KEYS = {"ĞºĞ¾Ğ½Ñ„ĞµÑ€ĞµĞ½Ñ†", "Ñ„Ğ¾Ñ€ÑƒĞ¼", "Ğ²Ñ‹ÑÑ‚Ğ°Ğ²Ğº", "ÑĞµĞ¼Ğ¸Ğ½Ğ°Ñ€", "webinar", "ĞºÑƒÑ€Ñ", "devcon"}
INCLUDE = set(ONEC_KEYS) | {
    "ai", "devops", "Ğ¾Ğ±Ğ»Ğ°Ñ‡", "Ñ†Ğ¸Ñ„Ñ€Ğ¾Ğ²", "Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†", "Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†", "kubernetes",
    "crm", "Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°", "Ğ¼Ğ¾Ğ´ĞµÑ€Ğ½Ğ¸Ğ·Ğ°Ñ†", "Ñ€ĞµĞ»Ğ¸Ğ·", "Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½", "ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†",
    "erp", "ÑƒÑ…", "Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´ÑÑ‚Ğ²", "Ğ°Ğ³Ñ€Ğ°Ñ€", "Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»"
}
EXCLUDE = {"crypto", "iphone", "lifestyle", "ÑˆĞ¾ĞºĞ¾Ğ»Ğ°Ğ´", "Ğ°Ğ²Ñ‚Ğ¾", "Ğ±Ğ°Ğ½ĞºĞ¾Ğ¼Ğ°Ñ‚"}

RSS_FEEDS = [
    "https://habr.com/ru/rss/all/all/?fl=ru", "https://vc.ru/rss", "https://www.rbc.ru/technology/rss/full/",
    "https://tadviser.ru/index.php/Ğ¡Ñ‚Ğ°Ñ‚ÑŒÑ:ĞĞ¾Ğ²Ğ¾ÑÑ‚Ğ¸?feed=rss", "https://novostiitkanala.ru/feed/",
    "https://www.kommersant.ru/RSS/section-tech.xml", "https://1c.ru/news/all.rss",
    "https://infostart.ru/rss/news/", "https://trends.rbc.ru/trends.rss", "https://rusbase.com/feed/",
]

# â”€â”€â”€ helpers â”€â”€â”€
plain = lambda html: BeautifulSoup(html, "html.parser").get_text(" ").lower()
async def fetch_html(url, cl):
    try:
        r = await cl.get(url, timeout=8)
        return r.text if r.status_code == 200 else None
    except Exception:
        return None

# â”€â”€â”€ 0. COLLECT â”€â”€â”€

def collect_raw():
    onec, other, events = [], [], []
    for feed in RSS_FEEDS:
        try:
            fp = feedparser.parse(feed)
        except Exception:
            continue
        for e in fp.entries[:MAX_PER_FEED]:
            link, title = e.get("link", ""), e.get("title", "")
            date_str = (e.get("published") or e.get("updated") or "")[:10]
            try:
                d = dt.datetime.strptime(date_str, "%Y-%m-%d")
            except Exception:
                d = dt.datetime.utcnow()
            if d < CUTOFF:
                continue
            rec = {"title": title, "url": link, "date": d.strftime("%d.%m.%Y"), "t": title.lower()}
            if any(k in rec["t"] for k in EVENT_KEYS):
                events.append(rec); continue
            (onec if urlparse(link).netloc in ONEC_DOMAINS or any(k in rec["t"] for k in ONEC_KEYS) else other).append(rec)
    return onec, other, events

# â”€â”€â”€ 1. TITLE FILTER â”€â”€â”€

def title_filter(lst):
    return [a for a in lst if not any(w in a["t"] for w in EXCLUDE) and any(k in a["t"] for k in INCLUDE)]

# â”€â”€â”€ 2. BODY FILTER â”€â”€â”€
async def body_filter(cand):
    subset = cand[:MAX_HTML]
    async with httpx.AsyncClient(follow_redirects=True, headers={"User-Agent": "Mozilla/5.0"}) as cl:
        pages = await asyncio.gather(*[fetch_html(a["url"], cl) for a in subset])
    out = []
    for art, html in zip(subset, pages):
        is_onec = urlparse(art["url"]).netloc in ONEC_DOMAINS or any(k in art["t"] for k in ONEC_KEYS)
        if not html:
            continue
        if is_onec or any(k in plain(html) for k in INCLUDE):
            out.append(art)
    return out

# â”€â”€â”€ 3. GPT RANK â”€â”€â”€

def gpt_rank(pool):
    prompt = "ĞÑ†ĞµĞ½Ğ¸ Ğ¿Ğ¾ ÑˆĞºĞ°Ğ»Ğµ 0â€‘10 Ğ²Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ° 1Ğ¡. ĞÑ‚Ğ²ĞµÑ‚ JSON {\"idx\":score}."
    mini = [{"idx": i, "title": a["title"], "url": a["url"]} for i, a in enumerate(pool)]
    try:
        resp = client.chat.completions.create(model=MODEL, messages=[{"role": "user", "content": prompt + json.dumps(mini, ensure_ascii=False)}], temperature=0, max_tokens=300)
        scores = json.loads(resp.choices[0].message.content)
    except Exception:
        scores = {str(i): 5 for i in range(len(pool))}
    return sorted(pool, key=lambda x: -scores.get(str(pool.index(x)), 0))

# â”€â”€â”€ 4. LAYOUT â”€â”€â”€

def layout(news_onec, news_other, events):
    need_onec = max(1, int(DIGEST_MAX * PERC_ONEC))
    news = (news_onec[:need_onec] + news_other)[:DIGEST_MAX]
    return news, events[:3]

# â”€â”€â”€ PROMPT â”€â”€â”€

def build_prompt(news, evnts):
    today = dt.datetime.now(TZ).strftime("%d %b %Y")
    return textwrap.dedent(f"""
        Ğ¢Ñ‹ â€” Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¾Ñ€ B2Bâ€‘Ğ´Ğ°Ğ¹Ğ´Ğ¶ĞµÑÑ‚Ğ° Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ¾Ğ² 1Ğ¡. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ JSON, Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ²Ñ‹Ğ´ÑƒĞ¼Ñ‹Ğ²Ğ°Ğ¹.
        Ğ¡ĞµĞºÑ†Ğ¸Ğ¸: ğŸŒ/ğŸ‡·ğŸ‡º/ğŸŸ¡/ğŸª. Ğ•ÑĞ»Ğ¸ ÑĞµĞºÑ†Ğ¸Ñ Ğ¿ÑƒÑÑ‚Ğ° â€” Ğ²ÑÑ‚Ğ°Ğ²ÑŒ ÑÑ‚Ñ€Ğ¾ĞºÑƒ Â«Ğ±ĞµĞ· â€¦Â».
        Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: 8â€‘12 Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚ĞµĞ¹ (â‰¥40â€¯% 1Ğ¡) + Ğ´Ğ¾ 3 ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹. Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ ÑÑ‚Ñ€Ğ¾ĞºĞ¸: - <b>Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº</b> â€” 1â€‘2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ. <a href=\"url\">Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº</a> (DD.MM.YYYY)
        Ğ’ ĞºĞ¾Ğ½Ñ†Ğµ "ğŸ’¡ <b>Insight</b>:" â€” 2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ.
        JSON_NEWS: ```{json.dumps(news, ensure_ascii=False)}```
        JSON_EVENTS: ```{json.dumps(evnts, ensure_ascii=False)}```
    """).strip()

# â”€â”€â”€ SEND â”€â”€â”€

def sanitize(txt):
    txt = re.sub(r'href="([^"]+)"', lambda m: f'href=\"{m.group(1).replace("&", "&amp;")}\"', txt)
    parts = re.split(r'(<[^>]+>)', txt)
    return ''.join(p if p.startswith('<') else _html.escape(p) for p in parts)


def send(html):
    if not html.strip():
        return
    api = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    for i in range(0, len(html), 3800):
        chunk = sanitize(html[i:i + 3800])
        requests.post(api, json={"
